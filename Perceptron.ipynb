{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Реализовать обучение линейной регрессии для задачи boston house prices (https://www.kaggle.com/vikrishnan/boston-house-prices) с использованием torch’а\n",
    "\n",
    "** Реализоыать наивный баесовский классификатор для MNIST (взяв всего 2 цифры “1” и “2”) сравнить с sclearn’овским\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston['data']\n",
    "target = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor\n",
    "data  = torch.tensor(data).float()[:-10]\n",
    "target = torch.tensor(target).float()[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-382-36118362919a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val = torch.tensor(data).float()[-10:]\n",
      "<ipython-input-382-36118362919a>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val = torch.tensor(target).float()[-10:]\n"
     ]
    }
   ],
   "source": [
    "X_val = torch.tensor(data).float()[-10:]\n",
    "y_val = torch.tensor(target).float()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8955e-01, 0.0000e+00, 1.0590e+01, 0.0000e+00, 4.8900e-01, 5.4120e+00,\n",
      "         9.8000e+00, 3.5875e+00, 4.0000e+00, 2.7700e+02, 1.8600e+01, 3.4893e+02,\n",
      "         2.9550e+01],\n",
      "        [2.0090e-02, 9.5000e+01, 2.6800e+00, 0.0000e+00, 4.1610e-01, 8.0340e+00,\n",
      "         3.1900e+01, 5.1180e+00, 4.0000e+00, 2.2400e+02, 1.4700e+01, 3.9055e+02,\n",
      "         2.8800e+00],\n",
      "        [7.0226e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.1800e-01, 6.0060e+00,\n",
      "         9.5300e+01, 1.8746e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.1998e+02,\n",
      "         1.5700e+01],\n",
      "        [1.4932e-01, 2.5000e+01, 5.1300e+00, 0.0000e+00, 4.5300e-01, 5.7410e+00,\n",
      "         6.6200e+01, 7.2254e+00, 8.0000e+00, 2.8400e+02, 1.9700e+01, 3.9511e+02,\n",
      "         1.3150e+01],\n",
      "        [2.5941e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.7900e-01, 5.3040e+00,\n",
      "         8.9100e+01, 1.6475e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 1.2736e+02,\n",
      "         2.6640e+01],\n",
      "        [3.1533e-01, 0.0000e+00, 6.2000e+00, 0.0000e+00, 5.0400e-01, 8.2660e+00,\n",
      "         7.8300e+01, 2.8944e+00, 8.0000e+00, 3.0700e+02, 1.7400e+01, 3.8505e+02,\n",
      "         4.1400e+00],\n",
      "        [1.1460e-01, 2.0000e+01, 6.9600e+00, 0.0000e+00, 4.6400e-01, 6.5380e+00,\n",
      "         5.8700e+01, 3.9175e+00, 3.0000e+00, 2.2300e+02, 1.8600e+01, 3.9496e+02,\n",
      "         7.7300e+00],\n",
      "        [1.3075e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.8000e-01, 5.7130e+00,\n",
      "         5.6700e+01, 2.8237e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9690e+02,\n",
      "         1.4760e+01],\n",
      "        [2.5387e-01, 0.0000e+00, 6.9100e+00, 0.0000e+00, 4.4800e-01, 5.3990e+00,\n",
      "         9.5300e+01, 5.8700e+00, 3.0000e+00, 2.3300e+02, 1.7900e+01, 3.9690e+02,\n",
      "         3.0810e+01],\n",
      "        [8.7168e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.9300e-01, 6.4710e+00,\n",
      "         9.8800e+01, 1.7257e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9198e+02,\n",
      "         1.7120e+01]]) tensor([23.7000, 50.0000, 14.2000, 18.7000, 10.4000, 44.8000, 24.4000, 20.1000,\n",
      "        14.4000, 13.1000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "dataset = TensorDataset(data, target)\n",
    "\n",
    "# Randomly reading mini-batches\n",
    "data_iter = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "# Read a batch to see how it works\n",
    "for X, y in data_iter:\n",
    "    print(X,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.normal(m.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.constant(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0202,  0.1492, -0.1038,  0.1236,  0.0328, -0.1202, -0.0739, -0.1996,\n",
       "         -0.0642,  0.1251,  0.0479, -0.2722, -0.0577]], requires_grad=True)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1446], requires_grad=True)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.data.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 3312.565674\n",
      "w tensor([[ 0.0248,  0.1868, -0.0645,  0.1516,  0.0754, -0.0764, -0.0320, -0.1548,\n",
      "         -0.0306,  0.1660,  0.0912, -0.2273, -0.0169]])\n",
      "b tensor([0.1882])\n",
      "epoch 2, loss 2270.008789\n",
      "w tensor([[-0.0097,  0.2191, -0.0525,  0.1711,  0.0994, -0.0474, -0.0103, -0.1215,\n",
      "         -0.0393,  0.1810,  0.1176, -0.1954, -0.0024]])\n",
      "b tensor([0.2162])\n",
      "epoch 3, loss 1858.005615\n",
      "w tensor([[-0.0500,  0.2432, -0.0616,  0.1845,  0.1086, -0.0303, -0.0047, -0.0974,\n",
      "         -0.0732,  0.1745,  0.1308, -0.1732, -0.0062]])\n",
      "b tensor([0.2317])\n",
      "epoch 4, loss 1517.182617\n",
      "w tensor([[-0.0858,  0.2667, -0.0750,  0.2006,  0.1150, -0.0152, -0.0019, -0.0754,\n",
      "         -0.1078,  0.1639,  0.1413, -0.1528, -0.0144]])\n",
      "b tensor([0.2450])\n",
      "epoch 5, loss 1218.885254\n",
      "w tensor([[-0.1203,  0.2852, -0.0900,  0.2147,  0.1185, -0.0025, -0.0019, -0.0558,\n",
      "         -0.1426,  0.1497,  0.1495, -0.1344, -0.0255]])\n",
      "b tensor([0.2559])\n",
      "epoch 6, loss 961.955994\n",
      "w tensor([[-0.1545,  0.3031, -0.1047,  0.2282,  0.1227,  0.0104, -0.0011, -0.0369,\n",
      "         -0.1736,  0.1366,  0.1576, -0.1158, -0.0367]])\n",
      "b tensor([0.2669])\n",
      "epoch 7, loss 766.521545\n",
      "w tensor([[-0.1812,  0.3164, -0.1166,  0.2424,  0.1265,  0.0223,  0.0007, -0.0203,\n",
      "         -0.2002,  0.1248,  0.1652, -0.0995, -0.0454]])\n",
      "b tensor([0.2770])\n",
      "epoch 8, loss 597.351257\n",
      "w tensor([[-2.0753e-01,  3.2771e-01, -1.3008e-01,  2.5376e-01,  1.2893e-01,\n",
      "          3.2693e-02,  2.6953e-04, -5.0614e-03, -2.2686e-01,  1.1166e-01,\n",
      "          1.7118e-01, -8.4191e-02, -5.6149e-02]])\n",
      "b tensor([0.2855])\n",
      "epoch 9, loss 464.561188\n",
      "w tensor([[-0.2297,  0.3365, -0.1406,  0.2673,  0.1327,  0.0435,  0.0022,  0.0087,\n",
      "         -0.2492,  0.1012,  0.1780, -0.0689, -0.0652]])\n",
      "b tensor([0.2947])\n",
      "epoch 10, loss 369.276428\n",
      "w tensor([[-0.2482,  0.3407, -0.1492,  0.2812,  0.1360,  0.0530,  0.0040,  0.0198,\n",
      "         -0.2681,  0.0918,  0.1836, -0.0563, -0.0734]])\n",
      "b tensor([0.3024])\n",
      "epoch 11, loss 292.118011\n",
      "w tensor([[-0.2659,  0.3427, -0.1580,  0.2916,  0.1386,  0.0613,  0.0054,  0.0291,\n",
      "         -0.2865,  0.0819,  0.1883, -0.0448, -0.0814]])\n",
      "b tensor([0.3091])\n",
      "epoch 12, loss 235.996689\n",
      "w tensor([[-0.2804,  0.3404, -0.1643,  0.3035,  0.1413,  0.0690,  0.0076,  0.0366,\n",
      "         -0.3019,  0.0738,  0.1926, -0.0345, -0.0890]])\n",
      "b tensor([0.3153])\n",
      "epoch 13, loss 194.722046\n",
      "w tensor([[-0.2925,  0.3383, -0.1687,  0.3166,  0.1451,  0.0770,  0.0109,  0.0435,\n",
      "         -0.3140,  0.0677,  0.1976, -0.0249, -0.0952]])\n",
      "b tensor([0.3218])\n",
      "epoch 14, loss 164.119736\n",
      "w tensor([[-0.3025,  0.3303, -0.1728,  0.3288,  0.1474,  0.0832,  0.0133,  0.0473,\n",
      "         -0.3249,  0.0612,  0.2007, -0.0173, -0.1016]])\n",
      "b tensor([0.3264])\n",
      "epoch 15, loss 141.459320\n",
      "w tensor([[-0.3102,  0.3232, -0.1759,  0.3396,  0.1505,  0.0894,  0.0165,  0.0508,\n",
      "         -0.3334,  0.0562,  0.2042, -0.0100, -0.1073]])\n",
      "b tensor([0.3313])\n",
      "epoch 16, loss 124.921829\n",
      "w tensor([[-0.3168,  0.3145, -0.1787,  0.3485,  0.1525,  0.0944,  0.0187,  0.0525,\n",
      "         -0.3413,  0.0509,  0.2064, -0.0046, -0.1137]])\n",
      "b tensor([0.3348])\n",
      "epoch 17, loss 112.080139\n",
      "w tensor([[-0.3220,  0.3049, -0.1808,  0.3601,  0.1552,  0.0997,  0.0220,  0.0538,\n",
      "         -0.3476,  0.0469,  0.2090,  0.0008, -0.1189]])\n",
      "b tensor([0.3387])\n",
      "epoch 18, loss 102.765526\n",
      "w tensor([[-0.3253,  0.2930, -0.1816,  0.3708,  0.1577,  0.1044,  0.0249,  0.0537,\n",
      "         -0.3520,  0.0433,  0.2110,  0.0050, -0.1241]])\n",
      "b tensor([0.3419])\n",
      "epoch 19, loss 95.441635\n",
      "w tensor([[-0.3255,  0.2801, -0.1821,  0.3805,  0.1602,  0.1089,  0.0283,  0.0524,\n",
      "         -0.3548,  0.0404,  0.2129,  0.0086, -0.1290]])\n",
      "b tensor([0.3448])\n",
      "epoch 20, loss 89.758469\n",
      "w tensor([[-0.3268,  0.2685, -0.1833,  0.3917,  0.1623,  0.1132,  0.0310,  0.0516,\n",
      "         -0.3577,  0.0374,  0.2143,  0.0117, -0.1350]])\n",
      "b tensor([0.3474])\n",
      "epoch 21, loss 85.343948\n",
      "w tensor([[-0.3263,  0.2581, -0.1826,  0.4020,  0.1648,  0.1173,  0.0341,  0.0505,\n",
      "         -0.3596,  0.0355,  0.2161,  0.0146, -0.1393]])\n",
      "b tensor([0.3502])\n",
      "epoch 22, loss 81.639854\n",
      "w tensor([[-0.3248,  0.2455, -0.1820,  0.4119,  0.1673,  0.1214,  0.0371,  0.0482,\n",
      "         -0.3598,  0.0338,  0.2175,  0.0168, -0.1441]])\n",
      "b tensor([0.3527])\n",
      "epoch 23, loss 78.848732\n",
      "w tensor([[-0.3233,  0.2340, -0.1815,  0.4213,  0.1700,  0.1256,  0.0403,  0.0465,\n",
      "         -0.3595,  0.0327,  0.2193,  0.0192, -0.1486]])\n",
      "b tensor([0.3554])\n",
      "epoch 24, loss 76.032158\n",
      "w tensor([[-0.3225,  0.2236, -0.1824,  0.4307,  0.1715,  0.1292,  0.0421,  0.0441,\n",
      "         -0.3602,  0.0303,  0.2198,  0.0205, -0.1551]])\n",
      "b tensor([0.3571])\n",
      "epoch 25, loss 73.792488\n",
      "w tensor([[-0.3178,  0.2117, -0.1815,  0.4418,  0.1737,  0.1330,  0.0447,  0.0410,\n",
      "         -0.3590,  0.0292,  0.2206,  0.0217, -0.1607]])\n",
      "b tensor([0.3591])\n",
      "epoch 26, loss 72.483559\n",
      "w tensor([[-0.3152,  0.2026, -0.1802,  0.4520,  0.1766,  0.1374,  0.0477,  0.0393,\n",
      "         -0.3574,  0.0291,  0.2225,  0.0236, -0.1654]])\n",
      "b tensor([0.3619])\n",
      "epoch 27, loss 70.351166\n",
      "w tensor([[-0.3116,  0.1917, -0.1805,  0.4612,  0.1784,  0.1412,  0.0496,  0.0362,\n",
      "         -0.3563,  0.0274,  0.2229,  0.0244, -0.1717]])\n",
      "b tensor([0.3636])\n",
      "epoch 28, loss 69.069084\n",
      "w tensor([[-0.3087,  0.1840, -0.1811,  0.4720,  0.1801,  0.1449,  0.0509,  0.0338,\n",
      "         -0.3550,  0.0260,  0.2233,  0.0250, -0.1788]])\n",
      "b tensor([0.3654])\n",
      "epoch 29, loss 68.099739\n",
      "w tensor([[-0.3041,  0.1750, -0.1800,  0.4809,  0.1830,  0.1497,  0.0534,  0.0317,\n",
      "         -0.3522,  0.0262,  0.2251,  0.0265, -0.1838]])\n",
      "b tensor([0.3682])\n",
      "epoch 30, loss 66.857498\n",
      "w tensor([[-0.2995,  0.1677, -0.1801,  0.4932,  0.1848,  0.1536,  0.0548,  0.0294,\n",
      "         -0.3500,  0.0253,  0.2256,  0.0269, -0.1910]])\n",
      "b tensor([0.3701])\n",
      "epoch 31, loss 65.962685\n",
      "w tensor([[-0.2967,  0.1619, -0.1812,  0.5022,  0.1864,  0.1578,  0.0558,  0.0274,\n",
      "         -0.3489,  0.0238,  0.2259,  0.0274, -0.1987]])\n",
      "b tensor([0.3720])\n",
      "epoch 32, loss 65.126808\n",
      "w tensor([[-0.2915,  0.1555, -0.1809,  0.5143,  0.1893,  0.1628,  0.0579,  0.0255,\n",
      "         -0.3458,  0.0238,  0.2273,  0.0287, -0.2051]])\n",
      "b tensor([0.3748])\n",
      "epoch 33, loss 64.377228\n",
      "w tensor([[-0.2870,  0.1500, -0.1811,  0.5249,  0.1912,  0.1672,  0.0590,  0.0233,\n",
      "         -0.3427,  0.0235,  0.2280,  0.0288, -0.2127]])\n",
      "b tensor([0.3769])\n",
      "epoch 34, loss 64.114166\n",
      "w tensor([[-0.2824,  0.1435, -0.1825,  0.5355,  0.1922,  0.1707,  0.0592,  0.0200,\n",
      "         -0.3408,  0.0219,  0.2276,  0.0284, -0.2207]])\n",
      "b tensor([0.3781])\n",
      "epoch 35, loss 63.467175\n",
      "w tensor([[-0.2774,  0.1402, -0.1815,  0.5459,  0.1959,  0.1767,  0.0614,  0.0198,\n",
      "         -0.3363,  0.0232,  0.2301,  0.0301, -0.2262]])\n",
      "b tensor([0.3820])\n",
      "epoch 36, loss 62.520538\n",
      "w tensor([[-0.2730,  0.1338, -0.1826,  0.5553,  0.1970,  0.1804,  0.0615,  0.0165,\n",
      "         -0.3340,  0.0218,  0.2296,  0.0293, -0.2352]])\n",
      "b tensor([0.3832])\n",
      "epoch 37, loss 61.968403\n",
      "w tensor([[-0.2683,  0.1304, -0.1828,  0.5681,  0.1991,  0.1855,  0.0621,  0.0148,\n",
      "         -0.3317,  0.0213,  0.2303,  0.0299, -0.2433]])\n",
      "b tensor([0.3857])\n",
      "epoch 38, loss 61.327690\n",
      "w tensor([[-0.2640,  0.1276, -0.1835,  0.5778,  0.2017,  0.1910,  0.0633,  0.0139,\n",
      "         -0.3284,  0.0212,  0.2316,  0.0306, -0.2509]])\n",
      "b tensor([0.3887])\n",
      "epoch 39, loss 61.454037\n",
      "w tensor([[-0.2577,  0.1243, -0.1851,  0.5892,  0.2034,  0.1957,  0.0635,  0.0115,\n",
      "         -0.3254,  0.0201,  0.2317,  0.0301, -0.2595]])\n",
      "b tensor([0.3907])\n",
      "epoch 40, loss 60.423428\n",
      "w tensor([[-0.2517,  0.1213, -0.1841,  0.5990,  0.2071,  0.2020,  0.0654,  0.0109,\n",
      "         -0.3207,  0.0214,  0.2338,  0.0314, -0.2663]])\n",
      "b tensor([0.3946])\n",
      "epoch 41, loss 60.697998\n",
      "w tensor([[-0.2483,  0.1200, -0.1841,  0.6103,  0.2101,  0.2081,  0.0665,  0.0102,\n",
      "         -0.3173,  0.0216,  0.2354,  0.0325, -0.2742]])\n",
      "b tensor([0.3980])\n",
      "epoch 42, loss 60.949490\n",
      "w tensor([[-0.2415,  0.1173, -0.1849,  0.6200,  0.2134,  0.2144,  0.0683,  0.0086,\n",
      "         -0.3135,  0.0217,  0.2368,  0.0330, -0.2814]])\n",
      "b tensor([0.4015])\n",
      "epoch 43, loss 58.872513\n",
      "w tensor([[-0.2374,  0.1155, -0.1873,  0.6332,  0.2144,  0.2191,  0.0674,  0.0065,\n",
      "         -0.3112,  0.0200,  0.2364,  0.0321, -0.2923]])\n",
      "b tensor([0.4031])\n",
      "epoch 44, loss 58.462643\n",
      "w tensor([[-0.2339,  0.1129, -0.1884,  0.6429,  0.2168,  0.2249,  0.0680,  0.0049,\n",
      "         -0.3077,  0.0195,  0.2372,  0.0321, -0.3015]])\n",
      "b tensor([0.4061])\n",
      "epoch 45, loss 58.026970\n",
      "w tensor([[-0.2288,  0.1128, -0.1891,  0.6575,  0.2193,  0.2309,  0.0680,  0.0037,\n",
      "         -0.3042,  0.0193,  0.2380,  0.0324, -0.3110]])\n",
      "b tensor([0.4091])\n",
      "epoch 46, loss 57.659245\n",
      "w tensor([[-0.2241,  0.1107, -0.1896,  0.6666,  0.2220,  0.2368,  0.0684,  0.0023,\n",
      "         -0.3003,  0.0191,  0.2389,  0.0323, -0.3189]])\n",
      "b tensor([0.4122])\n",
      "epoch 47, loss 57.107555\n",
      "w tensor([[-2.1835e-01,  1.0798e-01, -1.8923e-01,  6.8085e-01,  2.2519e-01,\n",
      "          2.4351e-01,  7.0312e-02,  2.7062e-04, -2.9613e-01,  1.9426e-02,\n",
      "          2.4013e-01,  3.2747e-02, -3.2819e-01]])\n",
      "b tensor([0.4157])\n",
      "epoch 48, loss 57.419338\n",
      "w tensor([[-0.2146,  0.1087, -0.1893,  0.6911,  0.2289,  0.2507,  0.0712,  0.0008,\n",
      "         -0.2930,  0.0198,  0.2422,  0.0339, -0.3349]])\n",
      "b tensor([0.4201])\n",
      "epoch 49, loss 56.312050\n",
      "w tensor([[-0.2097,  0.1066, -0.1910,  0.7038,  0.2309,  0.2565,  0.0712, -0.0018,\n",
      "         -0.2891,  0.0189,  0.2425,  0.0332, -0.3451]])\n",
      "b tensor([0.4226])\n",
      "epoch 50, loss 56.626640\n",
      "w tensor([[-0.2050,  0.1052, -0.1925,  0.7171,  0.2326,  0.2620,  0.0703, -0.0038,\n",
      "         -0.2863,  0.0178,  0.2425,  0.0323, -0.3551]])\n",
      "b tensor([0.4250])\n",
      "epoch 51, loss 57.393345\n",
      "w tensor([[-0.2014,  0.1040, -0.1938,  0.7295,  0.2354,  0.2687,  0.0705, -0.0056,\n",
      "         -0.2829,  0.0168,  0.2430,  0.0321, -0.3650]])\n",
      "b tensor([0.4282])\n",
      "epoch 52, loss 55.144329\n",
      "w tensor([[-0.1964,  0.1028, -0.1926,  0.7420,  0.2397,  0.2765,  0.0726, -0.0061,\n",
      "         -0.2776,  0.0183,  0.2454,  0.0331, -0.3721]])\n",
      "b tensor([0.4330])\n",
      "epoch 53, loss 55.092655\n",
      "w tensor([[-0.1929,  0.1020, -0.1936,  0.7549,  0.2424,  0.2830,  0.0727, -0.0084,\n",
      "         -0.2746,  0.0175,  0.2459,  0.0329, -0.3818]])\n",
      "b tensor([0.4361])\n",
      "epoch 54, loss 54.381931\n",
      "w tensor([[-0.1858,  0.1029, -0.1943,  0.7665,  0.2463,  0.2907,  0.0738, -0.0087,\n",
      "         -0.2701,  0.0180,  0.2478,  0.0332, -0.3898]])\n",
      "b tensor([0.4407])\n",
      "epoch 55, loss 54.128819\n",
      "w tensor([[-0.1822,  0.1022, -0.1932,  0.7789,  0.2503,  0.2985,  0.0754, -0.0096,\n",
      "         -0.2664,  0.0184,  0.2496,  0.0336, -0.3971]])\n",
      "b tensor([0.4452])\n",
      "epoch 56, loss 53.804096\n",
      "w tensor([[-0.1777,  0.1015, -0.1946,  0.7934,  0.2538,  0.3062,  0.0758, -0.0107,\n",
      "         -0.2617,  0.0183,  0.2513,  0.0340, -0.4069]])\n",
      "b tensor([0.4494])\n",
      "epoch 57, loss 53.433674\n",
      "w tensor([[-0.1755,  0.1000, -0.1961,  0.8056,  0.2564,  0.3130,  0.0758, -0.0123,\n",
      "         -0.2588,  0.0170,  0.2518,  0.0334, -0.4173]])\n",
      "b tensor([0.4527])\n",
      "epoch 58, loss 53.088917\n",
      "w tensor([[-0.1712,  0.1001, -0.1965,  0.8191,  0.2599,  0.3207,  0.0763, -0.0135,\n",
      "         -0.2553,  0.0168,  0.2532,  0.0335, -0.4250]])\n",
      "b tensor([0.4570])\n",
      "epoch 59, loss 52.590611\n",
      "w tensor([[-0.1670,  0.0999, -0.1961,  0.8347,  0.2639,  0.3288,  0.0773, -0.0144,\n",
      "         -0.2512,  0.0170,  0.2546,  0.0338, -0.4342]])\n",
      "b tensor([0.4615])\n",
      "epoch 60, loss 53.095028\n",
      "w tensor([[-0.1633,  0.0984, -0.1971,  0.8474,  0.2667,  0.3356,  0.0776, -0.0178,\n",
      "         -0.2475,  0.0160,  0.2548,  0.0329, -0.4439]])\n",
      "b tensor([0.4646])\n",
      "epoch 61, loss 52.062649\n",
      "w tensor([[-0.1605,  0.0973, -0.1969,  0.8596,  0.2714,  0.3446,  0.0786, -0.0179,\n",
      "         -0.2434,  0.0164,  0.2572,  0.0335, -0.4514]])\n",
      "b tensor([0.4700])\n",
      "epoch 62, loss 52.152897\n",
      "w tensor([[-0.1571,  0.0990, -0.1968,  0.8724,  0.2749,  0.3523,  0.0791, -0.0198,\n",
      "         -0.2408,  0.0158,  0.2580,  0.0331, -0.4604]])\n",
      "b tensor([0.4741])\n",
      "epoch 63, loss 51.580723\n",
      "w tensor([[-0.1531,  0.0994, -0.1963,  0.8858,  0.2803,  0.3622,  0.0811, -0.0198,\n",
      "         -0.2357,  0.0169,  0.2612,  0.0346, -0.4670]])\n",
      "b tensor([0.4804])\n",
      "epoch 64, loss 50.983341\n",
      "w tensor([[-0.1495,  0.0992, -0.1963,  0.8984,  0.2838,  0.3698,  0.0811, -0.0217,\n",
      "         -0.2321,  0.0167,  0.2622,  0.0337, -0.4765]])\n",
      "b tensor([0.4844])\n",
      "epoch 65, loss 50.797436\n",
      "w tensor([[-0.1468,  0.0997, -0.1956,  0.9108,  0.2883,  0.3789,  0.0824, -0.0222,\n",
      "         -0.2289,  0.0165,  0.2641,  0.0342, -0.4843]])\n",
      "b tensor([0.4897])\n",
      "epoch 66, loss 50.746784\n",
      "w tensor([[-0.1436,  0.0975, -0.1965,  0.9244,  0.2913,  0.3865,  0.0824, -0.0248,\n",
      "         -0.2261,  0.0153,  0.2646,  0.0331, -0.4937]])\n",
      "b tensor([0.4934])\n",
      "epoch 67, loss 50.253307\n",
      "w tensor([[-0.1398,  0.0990, -0.1947,  0.9386,  0.2965,  0.3955,  0.0839, -0.0257,\n",
      "         -0.2210,  0.0166,  0.2671,  0.0337, -0.5005]])\n",
      "b tensor([0.4992])\n",
      "epoch 68, loss 49.863110\n",
      "w tensor([[-0.1365,  0.0958, -0.1949,  0.9516,  0.3005,  0.4037,  0.0844, -0.0274,\n",
      "         -0.2170,  0.0163,  0.2686,  0.0335, -0.5089]])\n",
      "b tensor([0.5039])\n",
      "epoch 69, loss 49.755917\n",
      "w tensor([[-0.1349,  0.0994, -0.1966,  0.9657,  0.3039,  0.4122,  0.0840, -0.0289,\n",
      "         -0.2143,  0.0151,  0.2693,  0.0331, -0.5188]])\n",
      "b tensor([0.5084])\n",
      "epoch 70, loss 49.402935\n",
      "w tensor([[-0.1307,  0.0991, -0.1951,  0.9797,  0.3092,  0.4223,  0.0856, -0.0292,\n",
      "         -0.2092,  0.0161,  0.2720,  0.0338, -0.5264]])\n",
      "b tensor([0.5144])\n",
      "epoch 71, loss 49.498234\n",
      "w tensor([[-0.1287,  0.0965, -0.1960,  0.9914,  0.3127,  0.4305,  0.0858, -0.0318,\n",
      "         -0.2082,  0.0141,  0.2727,  0.0332, -0.5346]])\n",
      "b tensor([0.5188])\n",
      "epoch 72, loss 49.122257\n",
      "w tensor([[-0.1252,  0.0959, -0.1943,  1.0047,  0.3174,  0.4395,  0.0866, -0.0343,\n",
      "         -0.2037,  0.0144,  0.2741,  0.0327, -0.5417]])\n",
      "b tensor([0.5239])\n",
      "epoch 73, loss 48.607491\n",
      "w tensor([[-0.1219,  0.0948, -0.1928,  1.0224,  0.3228,  0.4494,  0.0883, -0.0343,\n",
      "         -0.1996,  0.0153,  0.2772,  0.0339, -0.5490]])\n",
      "b tensor([0.5303])\n",
      "epoch 74, loss 48.615395\n",
      "w tensor([[-0.1205,  0.0985, -0.1928,  1.0335,  0.3277,  0.4595,  0.0888, -0.0337,\n",
      "         -0.1969,  0.0150,  0.2795,  0.0346, -0.5559]])\n",
      "b tensor([0.5365])\n",
      "epoch 75, loss 48.267441\n",
      "w tensor([[-0.1192,  0.0968, -0.1936,  1.0474,  0.3308,  0.4668,  0.0884, -0.0371,\n",
      "         -0.1935,  0.0137,  0.2796,  0.0330, -0.5645]])\n",
      "b tensor([0.5401])\n",
      "epoch 76, loss 48.183544\n",
      "w tensor([[-0.1184,  0.0954, -0.1921,  1.0600,  0.3358,  0.4765,  0.0895, -0.0398,\n",
      "         -0.1909,  0.0136,  0.2813,  0.0325, -0.5710]])\n",
      "b tensor([0.5458])\n",
      "epoch 77, loss 47.794601\n",
      "w tensor([[-0.1124,  0.0951, -0.1905,  1.0737,  0.3420,  0.4874,  0.0915, -0.0392,\n",
      "         -0.1852,  0.0149,  0.2849,  0.0333, -0.5756]])\n",
      "b tensor([0.5530])\n",
      "epoch 78, loss 47.653561\n",
      "w tensor([[-0.1131,  0.0966, -0.1899,  1.0866,  0.3471,  0.4971,  0.0921, -0.0410,\n",
      "         -0.1825,  0.0146,  0.2866,  0.0336, -0.5831]])\n",
      "b tensor([0.5587])\n",
      "epoch 79, loss 47.100212\n",
      "w tensor([[-0.1100,  0.0954, -0.1904,  1.1000,  0.3513,  0.5060,  0.0924, -0.0427,\n",
      "         -0.1795,  0.0136,  0.2877,  0.0327, -0.5915]])\n",
      "b tensor([0.5637])\n",
      "epoch 80, loss 47.376572\n",
      "w tensor([[-0.1081,  0.0964, -0.1889,  1.1151,  0.3572,  0.5167,  0.0932, -0.0422,\n",
      "         -0.1754,  0.0146,  0.2911,  0.0334, -0.5961]])\n",
      "b tensor([0.5708])\n",
      "epoch 81, loss 47.285427\n",
      "w tensor([[-0.1053,  0.0947, -0.1872,  1.1307,  0.3622,  0.5264,  0.0947, -0.0447,\n",
      "         -0.1720,  0.0143,  0.2928,  0.0334, -0.6023]])\n",
      "b tensor([0.5766])\n",
      "epoch 82, loss 47.259697\n",
      "w tensor([[-0.1040,  0.0969, -0.1869,  1.1439,  0.3673,  0.5362,  0.0949, -0.0461,\n",
      "         -0.1688,  0.0142,  0.2945,  0.0336, -0.6086]])\n",
      "b tensor([0.5826])\n",
      "epoch 83, loss 46.546604\n",
      "w tensor([[-0.1016,  0.0950, -0.1875,  1.1547,  0.3710,  0.5450,  0.0938, -0.0483,\n",
      "         -0.1667,  0.0125,  0.2951,  0.0319, -0.6161]])\n",
      "b tensor([0.5873])\n",
      "epoch 84, loss 46.689777\n",
      "w tensor([[-0.1031,  0.0963, -0.1869,  1.1709,  0.3762,  0.5548,  0.0944, -0.0501,\n",
      "         -0.1647,  0.0116,  0.2968,  0.0320, -0.6221]])\n",
      "b tensor([0.5934])\n",
      "epoch 85, loss 45.969536\n",
      "w tensor([[-0.1013,  0.0950, -0.1846,  1.1844,  0.3816,  0.5646,  0.0952, -0.0526,\n",
      "         -0.1606,  0.0122,  0.2988,  0.0322, -0.6283]])\n",
      "b tensor([0.5994])\n",
      "epoch 86, loss 45.666145\n",
      "w tensor([[-0.0985,  0.0975, -0.1840,  1.1987,  0.3873,  0.5761,  0.0961, -0.0510,\n",
      "         -0.1575,  0.0124,  0.3021,  0.0326, -0.6340]])\n",
      "b tensor([0.6068])\n",
      "epoch 87, loss 45.542980\n",
      "w tensor([[-0.0949,  0.0946, -0.1828,  1.2079,  0.3920,  0.5852,  0.0963, -0.0547,\n",
      "         -0.1541,  0.0120,  0.3032,  0.0319, -0.6387]])\n",
      "b tensor([0.6122])\n",
      "epoch 88, loss 46.008102\n",
      "w tensor([[-0.0953,  0.0969, -0.1828,  1.2227,  0.3967,  0.5950,  0.0958, -0.0558,\n",
      "         -0.1517,  0.0109,  0.3047,  0.0315, -0.6444]])\n",
      "b tensor([0.6181])\n",
      "epoch 89, loss 45.142036\n",
      "w tensor([[-0.0946,  0.0968, -0.1809,  1.2394,  0.4026,  0.6057,  0.0971, -0.0570,\n",
      "         -0.1476,  0.0117,  0.3072,  0.0319, -0.6510]])\n",
      "b tensor([0.6248])\n",
      "epoch 90, loss 45.136852\n",
      "w tensor([[-0.0929,  0.0942, -0.1788,  1.2488,  0.4095,  0.6174,  0.0983, -0.0588,\n",
      "         -0.1437,  0.0123,  0.3103,  0.0322, -0.6534]])\n",
      "b tensor([0.6325])\n",
      "epoch 91, loss 45.013695\n",
      "w tensor([[-0.0911,  0.0913, -0.1780,  1.2638,  0.4137,  0.6266,  0.0981, -0.0622,\n",
      "         -0.1416,  0.0110,  0.3113,  0.0312, -0.6592]])\n",
      "b tensor([0.6379])\n",
      "epoch 92, loss 44.701942\n",
      "w tensor([[-0.0907,  0.0953, -0.1765,  1.2752,  0.4200,  0.6382,  0.0989, -0.0616,\n",
      "         -0.1387,  0.0115,  0.3142,  0.0321, -0.6625]])\n",
      "b tensor([0.6455])\n",
      "epoch 93, loss 44.488289\n",
      "w tensor([[-0.0892,  0.0963, -0.1760,  1.2915,  0.4255,  0.6489,  0.0997, -0.0635,\n",
      "         -0.1359,  0.0109,  0.3157,  0.0323, -0.6686]])\n",
      "b tensor([0.6520])\n",
      "epoch 94, loss 44.525242\n",
      "w tensor([[-0.0890,  0.0950, -0.1742,  1.3044,  0.4315,  0.6599,  0.1002, -0.0646,\n",
      "         -0.1324,  0.0112,  0.3183,  0.0323, -0.6738]])\n",
      "b tensor([0.6590])\n",
      "epoch 95, loss 46.605785\n",
      "w tensor([[-0.0858,  0.0948, -0.1754,  1.3160,  0.4348,  0.6684,  0.0987, -0.0684,\n",
      "         -0.1309,  0.0088,  0.3180,  0.0298, -0.6810]])\n",
      "b tensor([0.6634])\n",
      "epoch 96, loss 44.100365\n",
      "w tensor([[-0.0829,  0.0938, -0.1711,  1.3288,  0.4423,  0.6799,  0.1006, -0.0683,\n",
      "         -0.1253,  0.0112,  0.3223,  0.0312, -0.6818]])\n",
      "b tensor([0.6717])\n",
      "epoch 97, loss 43.876080\n",
      "w tensor([[-0.0845,  0.0955, -0.1718,  1.3431,  0.4473,  0.6905,  0.1008, -0.0702,\n",
      "         -0.1239,  0.0096,  0.3233,  0.0311, -0.6882]])\n",
      "b tensor([0.6780])\n",
      "epoch 98, loss 43.726295\n",
      "w tensor([[-0.0812,  0.0960, -0.1708,  1.3540,  0.4529,  0.7015,  0.1003, -0.0717,\n",
      "         -0.1208,  0.0095,  0.3255,  0.0310, -0.6931]])\n",
      "b tensor([0.6848])\n",
      "epoch 99, loss 43.495281\n",
      "w tensor([[-0.0813,  0.0967, -0.1682,  1.3682,  0.4586,  0.7121,  0.1001, -0.0734,\n",
      "         -0.1174,  0.0102,  0.3274,  0.0311, -0.6974]])\n",
      "b tensor([0.6914])\n",
      "epoch 100, loss 43.929710\n",
      "w tensor([[-0.0804,  0.0967, -0.1666,  1.3789,  0.4649,  0.7236,  0.1021, -0.0741,\n",
      "         -0.1147,  0.0107,  0.3301,  0.0315, -0.6996]])\n",
      "b tensor([0.6991])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        trainer.zero_grad()\n",
    "        l = loss(model.forward(X).reshape(-1), y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(model.forward(data).reshape(-1), target)\n",
    "    print('epoch %d, loss %f' % (epoch, l.item()))\n",
    "    print('w',model[0].weight.data)\n",
    "    print('b',model[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0804,  0.0967, -0.1666,  1.3789,  0.4649,  0.7236,  0.1021, -0.0741,\n",
       "         -0.1147,  0.0107,  0.3301,  0.0315, -0.6996]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6991])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0804,  0.0967, -0.1666,  1.3789,  0.4649,  0.7236,  0.1021, -0.0741,\n",
       "         -0.1147,  0.0107,  0.3301,  0.0315, -0.6996]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred 22, y_true 19.100000381469727, pred-true diff 3.634644\n",
      "y_pred 22, y_true 20.600000381469727, pred-true diff 1.695187\n",
      "y_pred 23, y_true 15.199999809265137, pred-true diff 8.019097\n",
      "y_pred 18, y_true 7.0, pred-true diff 11.023733\n",
      "y_pred 12, y_true 8.100000381469727, pred-true diff 4.853125\n",
      "y_pred 24, y_true 13.600000381469727, pred-true diff 10.461102\n",
      "y_pred 25, y_true 20.100000381469727, pred-true diff 5.896561\n",
      "y_pred 22, y_true 21.799999237060547, pred-true diff 0.935015\n",
      "y_pred 20, y_true 24.5, pred-true diff -3.884275\n",
      "y_pred 16, y_true 23.100000381469727, pred-true diff -7.020226\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,X_val.shape[0]):\n",
    "    y_pred = model(X_val[i]).reshape(-1)\n",
    "    l = y_pred - y_val[i]   \n",
    "    print('y_pred %d, y_true %s, pred-true diff %f' % (y_pred.item(), y_val[i].item(), l.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
